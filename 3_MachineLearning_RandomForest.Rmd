---
title: "Machine Learning - Random Forest"
author: "Carmen Rodriguez Cabrera"
date: "11/29/2021"
output:
  html_document: default
---

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(knitr)
library(tidyverse)
library(caret)
library(randomForest)
#install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
```

## Predicting Recipe Popularity 

```{r}
#LOAD DATASET
recipesdat<-read.csv(file = "recipes_final.csv")
#str(recipesdat) # 1142 recipes
```

###  Distributions of outcome

Initially we were interested in predicting rating, however, the distribution of ratings was left skewed as most recipes are highly rated with 4 or 5 stars (median = 4.98). This is simply because people who follow food blogs enjoy the recipes and so they are likely to rate them highly. Therefore, we decided to predict recipe popularity defined as the number of ratings `n_ratings` using recipe features as the predictors.

```{r message=FALSE, warning=FALSE}
recipesdat %>% ggplot(aes(x = rating)) + geom_histogram(color = "black", fill = "white") + labs( x = "User Ratings", y= "Counts", title = "Distribution of user ratings (Number of ratings)") 
# left skewed distribution- most recipes are highly rated --

```


```{r include=FALSE}
#Take a look at number of ratings
recipesdat %>% ggplot(aes(x = n_ratings)) + geom_histogram(color = "black", fill = "white", binwidth = 50) + labs( x = "Number of ratings", title = "Distribution of Recipe Popularity (Number of ratings)") 


#summary(recipesdat$n_ratings) # 25 NA's
#recipesdat %>% filter(n_ratings >= 60) %>% dplyr::select(recipe,n_ratings, rating)
#plot(recipesdat$n_ratings, recipesdat$rating)
#Concluded to remove the recipe with 2031 user ratings, and NA's

```


```{r}
#Remove missing and recipe with 2031
recipesdat<-recipesdat %>% filter(n_ratings != 2031) %>% drop_na(n_ratings) #1116
dist<-recipesdat %>% ggplot(aes(x = n_ratings)) + geom_histogram(color = "black", fill = "white", binwidth = 50) + labs( x = "Number of ratings", title = "Distribution of Recipe Popularity (Number of ratings)") 

dist
# ggsave("dist.png", limitsize = TRUE)

png("dist.png", width = 400, height = 400)
dist
dev.off()

```


### Partition data 

We use `createDataPartition` to split the  data into equally-sized training and test sets. 

```{r message=FALSE, warning=FALSE}
set.seed(123)
recipes_index_train = createDataPartition(y = recipesdat$n_ratings, 
                                  times = 1, p = 0.5, list = FALSE)
recipes_train = slice(recipesdat, recipes_index_train)
recipes_test = slice(recipesdat, -recipes_index_train)
```

### Exploratory Analysis 

Using the training set we  make some plots to help assess the relationship between recipe popularity  `n_ratings`, and each of the other features of interest in the data set. 

Looking at the scatterplots below we do not see any patterns  between recipe popularity and any features. This was further confirmed using a correlation matrix, where we can see that none of the features are highly correlated with recipe popularity `n_ratings`.

```{r message=FALSE, warning=FALSE}
scatter<-recipes_train%>% 
  gather(predictor, value, c(cook_time, prep_time, servings, n_ingredients, n_steps)) %>% 
  ggplot(aes(x = value, y = n_ratings)) + 
  geom_point() + 
  facet_wrap(~ predictor, scales = 'free_x', 
             labeller = 
               as_labeller(c("cook_time" = "How long it takes to cook", 
                             "prep_time" = "How long it takes to prepare", 
                             "servings" = "Number of servings recipe yields",
                            "n_ingredients" = "Number of ingredients",
                              "n_steps" = "Number of steps"))) + 
  xlab(NULL) + ylab("Recipe Popularity (Number of ratings)")

scatter

#ggsave("scatter.png", limitsize = TRUE)

png("scatter.png", width = 600, height = 400)
scatter
dev.off()


```


```{r message=FALSE, warning=FALSE}
my_data <-recipes_train %>% dplyr::select(n_ratings,cook_time, prep_time, servings, n_ingredients, n_steps)
corr<-chart.Correlation(my_data, histogram=TRUE, pch=19,)

png("corr.png", width = 400, height = 400)
corr
dev.off()


```
###  Preliminary assessment - fit a linear regression model 

```{r}
#Preliminary- no correlation between features of interest and recipe popularity (number of ratings)
fit_lm<-lm(n_ratings ~  cook_time + prep_time + n_ingredients + servings + 
                           n_steps, data = recipes_train)

summary(fit_lm)
```

Only `cook_time` is significantly associated with recipe popularity. More specifically, recipes with higher cook time have slightly higher number of ratings.


###  Random Forest 

In this section:

We conducted Random Forest regression to predict recipe popularity (number of ratings) of the recipe based on other features. 

a) Plotted the full model to illustrate the error rate as we average across more trees. This showed that our error rate stabilized with around 200 trees but continues to decrease slowly until around 300 or so trees.
  
```{r}
set.seed(123)
# Random forest
#First we fit a model with all predictors of interest
popularity<-randomForest(n_ratings ~  cook_time + prep_time + n_ingredients + servings + 
                           n_steps, mtry = 5, na.action = na.exclude, data = recipes_train)

popularity  # Does not perform well -- there is barely any corr between outcome and predictors

#Plotting the model will illustrate the error rate as we average across more trees and shows that our error rate stabilizes with around 200 trees but continues to decrease slowly until around 300 or so trees.
plot(popularity)
```

b)  Re-ran the model with 200 trees. 
```{r}
#Re-run model with only 200 trees
popularity1<-randomForest(n_ratings ~  cook_time + prep_time + n_ingredients + servings + 
                           n_steps, mtry = 5, ntree = 200, na.action = na.exclude, data = recipes_train)

```

c) Assessed performance in the test set

The mean square error for the prediction model is 6098.

```{r}

#How well does it perform on the test set?
prediction_fullmodel<- predict(popularity1, newdata = recipes_train)

plot(prediction_fullmodel, recipes_test$n_ratings, ylab =  "Recipe Popularity observed", xlab = "Predicted Recipe Popularity in full model") #that's not very good
abline(0,1)

mean((prediction_fullmodel - recipes_test$n_ratings)^2, na.rm = TRUE)

# png("fit.png")
# print(fit)
# dev.off()


```

d) Examined which features are the best predictors through variable importance analysis. 

We calculated the mean decrease Gini which is a measure of variable importance based on the Gini impurity index used for the calculation of splits in trees. The variables are presented from descending importance.

```{r}
# Variable importance
variable_importance <- importance(popularity1) 
varI_table <- data_frame(Feature = rownames(variable_importance),
                  Gini = variable_importance[,1]) %>%
                  arrange(desc(Gini))
varI_table

```


e) Re-fitting the model with only high importance variables- Reduced model

The mean square error decreased to 5517.4 when only including variables that are predictive.

```{r}
#Re-run model with only 200 trees
popularity2<-randomForest(n_ratings ~  cook_time  + n_ingredients, ntree = 200, na.action = na.exclude, data = recipes_train)

#How well does it perform on the test set?
prediction_reduced<- predict(popularity2, newdata = recipes_train)

plot(prediction_reduced, recipes_test$n_ratings, ylab =  "Recipe Popularity observed", xlab = "Predicted Recipe Popularity in reduced model") #that's not very good
abline(0,1)

mean((prediction_reduced - recipes_test$n_ratings)^2, na.rm = TRUE)

```


### Summary of results

-  Error rate of the full model  stabilized with around 200 trees but continues to decrease slowly until around 300 or so trees.

-  Model did not perform well in the test set. This is because as shown by the correlation matrix and preliminary analysis using linear regression only `cook_time` was correlated with recipe popularity `n_ratings`. Therefore, the random forest algorithm  is forced to choose amongst only "noise" variables at many of its splits leading to poor performance.   

- The two most predictive variables as determined by their Gini coefficient were: cook time and number of ingredients.
Reducing the model to only include important variables decreased the mean square error from  6098 to 5517.



### References
- http://developmentaldatascience.org/post/29-01-18_metaforest_no_effect/
- https://uc-r.github.io/random_forests
- https://stats.stackexchange.com/questions/447863/log-transforming-target-var-for-training-a-random-forest-regressor





